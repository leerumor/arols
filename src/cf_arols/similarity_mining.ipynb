{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "\n",
    "student_class = pd.read_csv('./data/student_kmeans.csv')\n",
    "student_class = student_class.set_index('id_student')\n",
    "student_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate user-item dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def generate_user_data():\n",
    "    user_train_data = {}\n",
    "    item_train_data = {}\n",
    "    test_data = {}\n",
    "    # create dataframe\n",
    "    for i in range(0, 5):\n",
    "        user_train_data[i] = {}\n",
    "        item_train_data[i] = {}\n",
    "        test_data[i] = {}\n",
    "    # read log file\n",
    "    data_file = open('./data/student_train.csv')\n",
    "    array_lines = csv.reader(data_file)\n",
    "    for line in array_lines:\n",
    "        user_id = int(line[1])\n",
    "        item_id = int(line[2])\n",
    "        if user_id not in student_class.index: \n",
    "            continue\n",
    "        cluster = int(student_class.loc[user_id, 'cluster'])\n",
    "        user_train_data[cluster].setdefault(user_id, {})\n",
    "        user_train_data[cluster][user_id].setdefault(item_id, 0)\n",
    "        user_train_data[cluster][user_id][item_id] += 1\n",
    "        item_train_data[cluster].setdefault(item_id, {})\n",
    "        item_train_data[cluster][item_id].setdefault(user_id, 0)\n",
    "        item_train_data[cluster][item_id][user_id] += 1\n",
    "    # read log file\n",
    "    data_file = open('./data/student_test.csv')\n",
    "    array_lines = csv.reader(data_file)\n",
    "    for line in array_lines:\n",
    "        user_id = int(line[1])\n",
    "        item_id = int(line[2])\n",
    "        if user_id not in student_class.index: \n",
    "            continue\n",
    "        cluster = int(student_class.loc[user_id, 'cluster'])\n",
    "        test_data[cluster].setdefault(user_id, {})\n",
    "        test_data[cluster][user_id].setdefault(item_id, 0)\n",
    "        test_data[cluster][user_id][item_id] += 1\n",
    "    # save files\n",
    "    np.save('./data/user_train_data.npy', user_train_data)\n",
    "    np.save('./data/item_train_data.npy', item_train_data)\n",
    "    np.save('./data/user_test_data.npy', test_data)\n",
    "    print('end of task')\n",
    "\n",
    "# read files\n",
    "def load_files(method):\n",
    "    train_data = np.load('./data/'+ method + '_train_data.npy').item()\n",
    "    test_data = np.load('./data/user_test_data.npy').item()\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance matrix function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_distances # 1-cos similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def pearson_distances(array1, array2):\n",
    "    return 1-pearsonr(array1, array2)\n",
    "\n",
    "def generate_distance_matrix(train, metric='euclidean'):\n",
    "    df = pd.DataFrame(0, index=train.keys(), columns=train.keys(), dtype=np.float32)\n",
    "    for index1 in train.keys():\n",
    "        for index2 in train.keys():\n",
    "            if df.at[index1,index2] > 0: continue\n",
    "            df.at[index1,index2] = distance(train[index1], train[index2])\n",
    "            df.at[index2,index1] = df.at[index1,index2]\n",
    "    df.fillna(max(df))\n",
    "    return df\n",
    "\n",
    "def distance(dict1, dict2, metric='euclidean'):\n",
    "    if metric=='euclidean': \n",
    "        fn = euclidean_distances\n",
    "    elif metric=='cosine':\n",
    "        fn = cosine_distances\n",
    "    elif metric=='pearson':\n",
    "        fn = pearson_distances\n",
    "    common = set(dict1.keys()) & set(dict2.keys())\n",
    "    if len(common) == 0: return float('NaN')\n",
    "    array1 = []\n",
    "    array2 = []\n",
    "    for key in common:\n",
    "        array1.append(dict1[key])\n",
    "        array2.append(dict2[key])\n",
    "    return fn(np.array(array1).reshape(-1, 1), np.array(array2).reshape(-1, 1))[0][0]\n",
    "\n",
    "def get_distance_matrix(name):\n",
    "    return pd.read_csv('./data/' + name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_files():\n",
    "    train_data, test_data = load_files('user')\n",
    "    for i in range(0, 5):\n",
    "        df = generate_distance_matrix(train_data[i], metric='euclidean')\n",
    "        df.to_csv('./data/user_euclidean_matrix_' + str(i) + '.csv')\n",
    "        print('user_euclidean_matrix...done')\n",
    "        df = generate_distance_matrix(train_data[i], metric='cosine')\n",
    "        df.to_csv('./data/user_cosine_matrix_' + str(i) + '.csv')\n",
    "        print('user_cosine_matrix...done')\n",
    "        df = generate_distance_matrix(train_data[i], metric='pearson')\n",
    "        df.to_csv('./data/user_pearsonn_matrix_' + str(i) + '.csv')\n",
    "        print('user_pearson_matrix...done')\n",
    "        \n",
    "    train_data, test_data = load_files('item')\n",
    "    for i in range(0, 5):\n",
    "        df = generate_distance_matrix(train_data[i], metric='euclidean')\n",
    "        df.to_csv('./data/item_euclidean_matrix_' + str(i) + '.csv')\n",
    "        print('item_euclidean_matrix...done')\n",
    "        df = generate_distance_matrix(train_data[i], metric='cosine')\n",
    "        df.to_csv('./data/item_cosine_matrix_' + str(i) + '.csv')\n",
    "        print('item_cosine_matrix...done')\n",
    "        df = generate_distance_matrix(train_data[i], metric='pearson')\n",
    "        df.to_csv('./data/item_pearsonn_matrix_' + str(i) + '.csv')\n",
    "        print('item_pearson_matrix...done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
